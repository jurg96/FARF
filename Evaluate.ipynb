{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# import warnings\n",
    "# warnings.ignore('all')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.measure import compare_psnr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import utils\n",
    "from modules import RotationLSH, IdentityLSH, PcaLSH, RandomForestClustRegressor, PictureResolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "n_samples=50000\n",
    "s=1/2\n",
    "n_estimators=10\n",
    "max_depth=15\n",
    "max_features=10\n",
    "\n",
    "augmented = False\n",
    "lsh = IdentityLSH()\n",
    "binary = True        # makes sense to use only for RotationLSH\n",
    "reg_type = 'ridge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img_array, s):\n",
    "    \"\"\"Crop image so that downscale-upscaling works well\"\"\"\n",
    "    img_array = img_array.copy()\n",
    "    shape = img_array.shape\n",
    "    new_shape = tuple(dim - (dim % int(1/s)) for dim in shape) # so that the HR and LR images have same size\n",
    "    img_array = img_array[0:new_shape[0], 0:new_shape[1]]\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/Set14'\n",
    "train_files = ['barbara.png', 'bridge.png', 'comic.png', 'pepper.png', 'man.png']\n",
    "\n",
    "def generate_trainset(n_samples, s, seed=7):\n",
    "    # patch_size is (9,9)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for file in train_files:\n",
    "        path = os.path.join(data_dir, file)\n",
    "        img_h = utils.load_image(path)\n",
    "        img_h = crop_image(img_h, s)\n",
    "        new_shape = img_h.shape\n",
    "        \n",
    "        img_l = utils.resize(utils.resize(img_h, s), 1/s) # downsample -> upsample\n",
    "\n",
    "        features = utils.extract_features(img_l, augmented=augmented)\n",
    "        img_out_delta = img_h - img_l\n",
    "        assert img_h.shape == img_l.shape == img_out_delta.shape == new_shape\n",
    "\n",
    "        x_ind = np.random.randint(0, new_shape[0]-9, size=n_samples//len(train_files))\n",
    "        y_ind = np.random.randint(0, new_shape[1]-9, size=n_samples//len(train_files))\n",
    "        for x, y in zip(x_ind, y_ind):\n",
    "            feat_patch = features[x:x+9, y:y+9]\n",
    "            delta_patch = img_out_delta[x:x+9, y:y+9]\n",
    "            X.append(feat_patch.flatten())\n",
    "            Y.append(delta_patch.flatten())\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_trainset(\n",
    "    n_samples=n_samples,\n",
    "    s=s,\n",
    "    seed=7\n",
    ")\n",
    "\n",
    "X = np.random.randn(500,324)\n",
    "Y = np.random.randn(500,81)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh.fit(X)\n",
    "X_comp = lsh.transform(X, binary=binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=os.listdir(data_dir))\n",
    "\n",
    "row_num = 0\n",
    "\n",
    "for min_samples_leaf in [128, 256]:\n",
    "    for alpha in [0.1, 0.5, 1, 2, 3, 4]:\n",
    "        df.loc[row_num, 'min_samples_leaf'] = min_samples_leaf\n",
    "        df.loc[row_num, 'reg_type'] = reg_type\n",
    "        df.loc[row_num, 'alpha'] = alpha\n",
    "\n",
    "        rf = RandomForestClustRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            n_jobs=None,\n",
    "            max_features=max_features,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            reg_type=reg_type,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        rf.fit(X, X_comp, Y)\n",
    "\n",
    "        for path_test in os.listdir(data_dir):\n",
    "            img_test = utils.load_image(os.path.join(data_dir,path_test))\n",
    "            img_test = crop_image(img_test, s)\n",
    "            x = utils.resize(utils.resize(img_test, s), 1/s)\n",
    "\n",
    "            pr = PictureResolver(rf, lsh, scaler)\n",
    "            y = pr.resolve(x, augmented=augmented)\n",
    "\n",
    "            nans = ~np.isnan(y)\n",
    "            y = y[nans.any(axis=1), :]\n",
    "            img_test = img_test[nans.any(axis=1), :]\n",
    "            y = y[:, nans.any(axis=0)]\n",
    "            img_test = img_test[:, nans.any(axis=0)]\n",
    "\n",
    "            df.loc[row_num, path_test] = compare_psnr(img_test, y, np.max(img_test) - np.min(img_test))\n",
    "\n",
    "        row_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CHANGE NAME TO STH MEANINGFUL\n",
    "\n",
    "df.to_csv('identity_ridge_augmented=False.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(-2,7).reshape(3,3)\n",
    "a.nonzero()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
